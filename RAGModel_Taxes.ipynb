{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def download_pdfs(pdf_links, folder_name):\n",
        "    # Download each PDF\n",
        "    for pdf_url in pdf_links:\n",
        "        pdf_name = pdf_url.split(\"/\")[-1]\n",
        "        file_path = os.path.join(folder_name, pdf_name)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"✅ Already downloaded: {pdf_name}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            pdf_res = requests.get(pdf_url)\n",
        "            pdf_res.raise_for_status()\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                f.write(pdf_res.content)\n",
        "            print(f\"📥 Downloaded: {pdf_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to download {pdf_name}: {e}\")\n",
        "\n",
        "    # Optional: Delay to be polite\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "tcPgXtdCiurH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3TqZugbaYCf",
        "outputId": "892fa28e-13b2-4474-cfeb-58998ab4d3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Scraping page 0...\n",
            "\n",
            "🔍 Scraping page 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-30080ba985a5>:35: DeprecationWarning: Call to deprecated method findChild. (Replaced by find) -- Deprecated since version 3.0.0.\n",
            "  tbody = table.findChild(\"tbody\", recursive=False)\n",
            "<ipython-input-4-30080ba985a5>:36: DeprecationWarning: Call to deprecated method findChildren. (Replaced by find_all) -- Deprecated since version 3.0.0.\n",
            "  form_rows = tbody.findChildren(\"tr\", recursive=False)\n",
            "<ipython-input-4-30080ba985a5>:41: DeprecationWarning: Call to deprecated method findChild. (Replaced by find) -- Deprecated since version 3.0.0.\n",
            "  form_desc_element = form.findChild(\"td\", attrs={\"headers\": \"view-name-table-column\"})\n",
            "<ipython-input-4-30080ba985a5>:52: DeprecationWarning: Call to deprecated method findChild. (Replaced by find) -- Deprecated since version 3.0.0.\n",
            "  form_desc_element = form.findChild(\"td\", attrs={\"headers\": \"view-name-table-column\"})\n",
            "<ipython-input-4-30080ba985a5>:55: DeprecationWarning: Call to deprecated method findChild. (Replaced by find) -- Deprecated since version 3.0.0.\n",
            "  english_forms.append(form.findChild(\"td\", attrs={\"headers\": \"view-uri-table-column\"}))\n",
            "<ipython-input-4-30080ba985a5>:60: DeprecationWarning: Call to deprecated method findChild. (Replaced by find) -- Deprecated since version 3.0.0.\n",
            "  urljoin(base_url, form.findChild(\"a\")[\"href\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Scraping page 2...\n",
            "\n",
            "🔍 Scraping page 3...\n",
            "\n",
            "🔍 Scraping page 4...\n",
            "\n",
            "🔍 Scraping page 5...\n",
            "\n",
            "🔍 Scraping page 6...\n",
            "\n",
            "🔍 Scraping page 7...\n",
            "\n",
            "🔍 Scraping page 8...\n",
            "\n",
            "🔍 Scraping page 9...\n",
            "\n",
            "🔍 Scraping page 10...\n",
            "\n",
            "🔍 Scraping page 11...\n",
            "\n",
            "🔍 Scraping page 12...\n",
            "\n",
            "🔍 Scraping page 13...\n",
            "\n",
            "🔍 Scraping page 14...\n",
            "\n",
            "🔍 Scraping page 15...\n",
            "\n",
            "🔍 Scraping page 16...\n",
            "\n",
            "🔍 Scraping page 17...\n",
            "\n",
            "🔍 Scraping page 18...\n",
            "\n",
            "🔍 Scraping page 19...\n",
            "\n",
            "🔍 Scraping page 20...\n",
            "\n",
            "🔍 Scraping page 21...\n",
            "\n",
            "🔍 Scraping page 22...\n",
            "\n",
            "🔍 Scraping page 23...\n",
            "\n",
            "🔍 Scraping page 24...\n",
            "\n",
            "🔍 Scraping page 25...\n",
            "\n",
            "🔍 Scraping page 26...\n",
            "\n",
            "🔍 Scraping page 27...\n",
            "\n",
            "🔍 Scraping page 28...\n",
            "\n",
            "🔍 Scraping page 29...\n",
            "\n",
            "🔍 Scraping page 30...\n",
            "\n",
            "🔍 Scraping page 31...\n",
            "\n",
            "🔍 Scraping page 32...\n",
            "\n",
            "🔍 Scraping page 33...\n",
            "\n",
            "🔍 Scraping page 34...\n",
            "\n",
            "🔍 Scraping page 35...\n",
            "\n",
            "🔍 Scraping page 36...\n",
            "\n",
            "🔍 Scraping page 37...\n",
            "\n",
            "🔍 Scraping page 38...\n",
            "\n",
            "🔍 Scraping page 39...\n",
            "\n",
            "🔍 Scraping page 40...\n",
            "\n",
            "🔍 Scraping page 41...\n",
            "\n",
            "🔍 Scraping page 42...\n",
            "\n",
            "🔍 Scraping page 43...\n",
            "\n",
            "🔍 Scraping page 44...\n",
            "\n",
            "🔍 Scraping page 45...\n",
            "\n",
            "🔍 Scraping page 46...\n",
            "\n",
            "🔍 Scraping page 47...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import re\n",
        "\n",
        "# Folder to save PDFs\n",
        "os.makedirs(\"irs_eng_pdfs\", exist_ok=True)\n",
        "os.makedirs(\"irs_multilang_pdfs\", exist_ok=True)\n",
        "\n",
        "base_url = \"https://www.irs.gov\"\n",
        "start_url = \"https://www.irs.gov/downloads/irs-pdf?page={}\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0\"\n",
        "}\n",
        "\n",
        "for page_num in range(58):  # Pages 0 to 57\n",
        "    print(f\"\\n🔍 Scraping page {page_num}...\")\n",
        "    url = start_url.format(page_num)\n",
        "\n",
        "    try:\n",
        "        res = requests.get(url, headers=headers)\n",
        "        res.raise_for_status()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to fetch page {page_num}: {e}\")\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "    #Find all elements from the table\n",
        "    table = soup.find(\"table\", attrs={\"class\": \"table table-striped tablesaw tablesaw-stack cols-4\"})\n",
        "\n",
        "    tbody = table.findChild(\"tbody\", recursive=False)\n",
        "    form_rows = tbody.findChildren(\"tr\", recursive=False)\n",
        "\n",
        "    single_language_regex = r\"\\((sp|ru|vie|zh-s|zh-t|de|ko|ht)\\)+\"\n",
        "    filtered_forms = []\n",
        "    for form in form_rows:\n",
        "            form_desc_element = form.findChild(\"td\", attrs={\"headers\": \"view-name-table-column\"})\n",
        "            form_desc = form_desc_element.contents[0]\n",
        "            if not bool(re.search(single_language_regex, form_desc)):\n",
        "                filtered_forms.append(form)\n",
        "\n",
        "    multi_language_regex = r\"\\(en-(sp|ru|vie|zh-s|zh-t|de|ko|ht)\\)+\"\n",
        "\n",
        "    english_forms = []\n",
        "    multilang_forms = []\n",
        "\n",
        "    for form in filtered_forms:\n",
        "            form_desc_element = form.findChild(\"td\", attrs={\"headers\": \"view-name-table-column\"})\n",
        "            form_desc = form_desc_element.contents[0]\n",
        "            if not bool(re.search(single_language_regex, form_desc)):\n",
        "                english_forms.append(form.findChild(\"td\", attrs={\"headers\": \"view-uri-table-column\"}))\n",
        "            else:\n",
        "                multilang_forms.append(form.findChild(\"td\", attrs={\"headers\": \"view-uri-table-column\"}))\n",
        "\n",
        "    eng_pdf_links = [\n",
        "            urljoin(base_url, form.findChild(\"a\")[\"href\"])\n",
        "            for form in english_forms\n",
        "        ]\n",
        "\n",
        "    multilang_pdf_links = [\n",
        "            urljoin(base_url, form.findChild(\"a\")[\"href\"])\n",
        "            for form in multilang_forms\n",
        "        ]\n",
        "\n",
        "download_pdfs(eng_pdf_links, \"irs_eng_pdfs\")\n",
        "download_pdfs(multilang_pdf_links, \"irs_multilang_pdfs\")\n",
        "\n",
        "print(\"\\n🎉 Done downloading all PDFs.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhV92siXeOLI",
        "outputId": "f0d35168-c23b-424c-9bf4-bddcab86635e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Copy folder to a new location in your Google Drive\n",
        "shutil.copytree('irs_all_pdfs', '/content/drive/MyDrive/UTD Coursework/Sem 4/AI Agents project/Tax project/irs_all_pdfs')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "07TLglXPeOys",
        "outputId": "57331a33-7fde-4969-a87a-1dcd024bd7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/UTD Coursework/Sem 4/AI Agents project/Tax project/irs_all_pdfs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "# Folder to save PDFs\n",
        "os.makedirs(\"irs_all_pdfs\", exist_ok=True)\n",
        "\n",
        "base_url = \"https://www.irs.gov\"\n",
        "start_url = \"https://www.irs.gov/downloads/irs-pdf?page={}\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0\"\n",
        "}\n",
        "\n",
        "for page_num in range(58):  # Pages 0 to 57\n",
        "    print(f\"\\n🔍 Scraping page {page_num}...\")\n",
        "    url = start_url.format(page_num)\n",
        "\n",
        "    try:\n",
        "        res = requests.get(url, headers=headers)\n",
        "        res.raise_for_status()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to fetch page {page_num}: {e}\")\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "    # Find all <a> tags with href ending in .pdf\n",
        "    links = soup.find_all(\"a\", href=True)\n",
        "\n",
        "print(links[0])"
      ],
      "metadata": {
        "id": "N8_bnV7Qem9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48aaa013-1f8f-4792-f14c-0bf96995fef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Scraping page 0...\n",
            "\n",
            "🔍 Scraping page 1...\n",
            "\n",
            "🔍 Scraping page 2...\n",
            "\n",
            "🔍 Scraping page 3...\n",
            "\n",
            "🔍 Scraping page 4...\n",
            "\n",
            "🔍 Scraping page 5...\n",
            "\n",
            "🔍 Scraping page 6...\n",
            "\n",
            "🔍 Scraping page 7...\n",
            "\n",
            "🔍 Scraping page 8...\n",
            "\n",
            "🔍 Scraping page 9...\n",
            "\n",
            "🔍 Scraping page 10...\n",
            "\n",
            "🔍 Scraping page 11...\n",
            "\n",
            "🔍 Scraping page 12...\n",
            "\n",
            "🔍 Scraping page 13...\n",
            "\n",
            "🔍 Scraping page 14...\n",
            "\n",
            "🔍 Scraping page 15...\n",
            "\n",
            "🔍 Scraping page 16...\n",
            "\n",
            "🔍 Scraping page 17...\n",
            "\n",
            "🔍 Scraping page 18...\n",
            "\n",
            "🔍 Scraping page 19...\n",
            "\n",
            "🔍 Scraping page 20...\n",
            "\n",
            "🔍 Scraping page 21...\n",
            "\n",
            "🔍 Scraping page 22...\n",
            "\n",
            "🔍 Scraping page 23...\n",
            "\n",
            "🔍 Scraping page 24...\n",
            "\n",
            "🔍 Scraping page 25...\n",
            "\n",
            "🔍 Scraping page 26...\n",
            "\n",
            "🔍 Scraping page 27...\n",
            "\n",
            "🔍 Scraping page 28...\n",
            "\n",
            "🔍 Scraping page 29...\n",
            "\n",
            "🔍 Scraping page 30...\n",
            "\n",
            "🔍 Scraping page 31...\n",
            "\n",
            "🔍 Scraping page 32...\n",
            "\n",
            "🔍 Scraping page 33...\n",
            "\n",
            "🔍 Scraping page 34...\n",
            "\n",
            "🔍 Scraping page 35...\n",
            "\n",
            "🔍 Scraping page 36...\n",
            "\n",
            "🔍 Scraping page 37...\n",
            "\n",
            "🔍 Scraping page 38...\n",
            "\n",
            "🔍 Scraping page 39...\n",
            "\n",
            "🔍 Scraping page 40...\n",
            "\n",
            "🔍 Scraping page 41...\n",
            "\n",
            "🔍 Scraping page 42...\n",
            "\n",
            "🔍 Scraping page 43...\n",
            "\n",
            "🔍 Scraping page 44...\n",
            "\n",
            "🔍 Scraping page 45...\n",
            "\n",
            "🔍 Scraping page 46...\n",
            "\n",
            "🔍 Scraping page 47...\n",
            "\n",
            "🔍 Scraping page 48...\n",
            "\n",
            "🔍 Scraping page 49...\n",
            "\n",
            "🔍 Scraping page 50...\n",
            "\n",
            "🔍 Scraping page 51...\n",
            "\n",
            "🔍 Scraping page 52...\n",
            "\n",
            "🔍 Scraping page 53...\n",
            "\n",
            "🔍 Scraping page 54...\n",
            "\n",
            "🔍 Scraping page 55...\n",
            "\n",
            "🔍 Scraping page 56...\n",
            "\n",
            "🔍 Scraping page 57...\n",
            "<a class=\"visually-hidden focusable skip-link\" href=\"#main-content\">\n",
            "      Skip to main content\n",
            "    </a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJAeQDe5OJJZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}